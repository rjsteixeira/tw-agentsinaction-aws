{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZT8gSSedw_1"
   },
   "source": [
    "# Agentic AI Workshop - AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQVfT22JTnVX"
   },
   "source": [
    "Credits: [Thoughtworks, 2025](https://Thoughtworks.com)\n",
    "\n",
    "[Ricardo Teixara](mailto:ricardo.teixera@thoughtworks.com), [Ben O'Mahony](\n",
    "ben.omahony@thoughtworks.com), [Yuvaraj Birari](mailto:Yuvaraj.Birari@thoughtworks.com), [Sebastian Werner](mailto:sebastian.werner@thoughtworks.com), [Danilo Sato](mailto:danilo.sato@thoughtworks.com) & [Kalyan Muthiah](mailto:kmuthiah@thoughtworks.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s28-0d7698aK"
   },
   "source": [
    "We use pydantic AI to save us from some of the heavy lifting, here are the docs for[Pydantic](https://ai.pydantic.dev/agents/).  \n",
    "Alternatives include [LangChain](https://www.langchain.com/langchain), and many more of variable maturity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhxCTN1HiL6g"
   },
   "source": [
    "# Set up procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZOZhStBuy5c"
   },
   "source": [
    "Test whether the API is working by listing the available GenAI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lists the available Amazon Bedrock models.\n",
    "\"\"\"\n",
    "import logging\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def list_foundation_models(bedrock_client):\n",
    "    \"\"\"\n",
    "    Gets a list of available Amazon Bedrock foundation models.\n",
    "\n",
    "    :return: The list of available bedrock foundation models.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = bedrock_client.list_foundation_models()\n",
    "        models = response[\"modelSummaries\"]\n",
    "        logger.info(\"Got %s foundation models.\", len(models))\n",
    "        return models\n",
    "\n",
    "    except ClientError:\n",
    "        logger.error(\"Couldn't list foundation models.\")\n",
    "        raise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Entry point for the example. Uses the AWS SDK for Python (Boto3)\n",
    "to create an Amazon Bedrock client. Then lists the available Bedrock models\n",
    "in the region set in the callers profile and credentials.\n",
    "\"\"\"\n",
    "\n",
    "bedrock_client = boto3.client(service_name=\"bedrock\")\n",
    "\n",
    "fm_models = list_foundation_models(bedrock_client)\n",
    "for model in fm_models:\n",
    "    print(f\"Model: {model['modelName']}\")\n",
    "    print(json.dumps(model, indent=2))\n",
    "    print(\"---------------------------\\n\")\n",
    "\n",
    "logger.info(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"pydantic-ai-slim[bedrock]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"pydantic-ai-slim[anthropic]\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60thMO6R9kmu"
   },
   "source": [
    "Fix the notebook vs. MCP async communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYXhwTwEdDoA"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2qYAMPz9q8h"
   },
   "source": [
    "Establish the model - Gemini flash is good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uikkwGbbcjIm",
    "outputId": "dde2dbd0-5eee-4725-e649-add1c4d8bab3"
   },
   "outputs": [],
   "source": [
    "\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.bedrock import BedrockConverseModel\n",
    "\n",
    "model = BedrockConverseModel('anthropic.claude-3-sonnet-20240229-v1:0')\n",
    "agent = Agent(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI8HsJsDiVIm"
   },
   "source": [
    "Test whether out model is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Fl632Ybnc62W",
    "outputId": "23e7e7fb-6a52-4d28-ff85-0594b2968ea8"
   },
   "outputs": [],
   "source": [
    "agent.run_sync(\"What is the major city on river Isar?\").output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgbPdf7XmOWX"
   },
   "source": [
    "Lets saved that for later - and do structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOg99sJcl_Oq"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class location(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "\n",
    "agent = Agent(model, output_type=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PFbvcH004-3"
   },
   "outputs": [],
   "source": [
    "location_result = agent.run_sync(\"What is the major city on river Isar?\").output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUSUeUSImaLw"
   },
   "source": [
    "and run it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DlLkTtYmmj5"
   },
   "outputs": [],
   "source": [
    "location_result = agent.run_sync(\"What is the major city on river Isar?\").output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "qCk5shKWm6XG",
    "outputId": "4187b8d3-5ed7-4e15-f2e5-d049a64573e8"
   },
   "outputs": [],
   "source": [
    "location_result.city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRUw_TtFil7F"
   },
   "source": [
    "# Set up our mock backend services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Awu4BaEKitWH"
   },
   "source": [
    "Our mock (aka fake) customer database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtCdR5aye62e"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "class DatabaseConn:\n",
    "    \"\"\"This is a fake database for example purposes.\n",
    "\n",
    "    In reality, you'd be connecting to an external database\n",
    "    (e.g. PostgreSQL) to get information about customers.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    async def customer_name(cls, *, id: int) -> str | None:\n",
    "        if id == 123:\n",
    "            return 'John'\n",
    "        else:\n",
    "            raise ValueError('Customer not found')\n",
    "\n",
    "    @classmethod\n",
    "    async def customer_order(cls, *, id: int, include_pending: bool) -> float:\n",
    "        if id == 123 and include_pending:\n",
    "            return {'order_id': 987, 'item': 'Really shady Sunglasses', 'quantity': 1, 'price': 23.42, 'ordered_on': '2025-05-25 23:42:05'}\n",
    "        else:\n",
    "            raise ValueError('Customer not found')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIvosU1SiyX_"
   },
   "source": [
    "Our support service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFGI_JBjfB7U"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from pydantic import Field\n",
    "\n",
    "@dataclass\n",
    "class SupportDependencies:\n",
    "    customer_id: int\n",
    "    db: DatabaseConn\n",
    "\n",
    "\n",
    "class SupportOutput(BaseModel):\n",
    "    support_advice: str = Field(description='Advice returned to the customer')\n",
    "    completed: bool = Field(description='Whether the problem has been solved')\n",
    "    urgency: int = Field(description='Urgency level of query', ge=0, le=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmUeQNG4i9p3"
   },
   "source": [
    "Construct our support agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKxvGY7Je2s-"
   },
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "support_agent = Agent(\n",
    "    model=model,\n",
    "    deps_type=SupportDependencies,\n",
    "    output_type=SupportOutput,\n",
    "    system_prompt=(\n",
    "        'You are a support agent in our market leading company, give the '\n",
    "        'customer support and judge the urgency level of their query. '\n",
    "        \"Reply using the customer's name.\"\n",
    "        'Be overly friendly and supportive.'\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rx_EFqgejqRH"
   },
   "source": [
    "Add the customer name to the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElrXuv3bfOgJ"
   },
   "outputs": [],
   "source": [
    "@support_agent.system_prompt\n",
    "async def add_customer_name(ctx: RunContext[SupportDependencies]) -> str:\n",
    "    customer_name = await ctx.deps.db.customer_name(id=ctx.deps.customer_id)\n",
    "    return f\"The customer's name is {customer_name!r}, their customer_id is {ctx.deps.customer_id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9iz8Brlj-BX"
   },
   "source": [
    "Add a tool as decorator to get the customer orders from the mock database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvjdwXdJfJlp"
   },
   "outputs": [],
   "source": [
    "@support_agent.tool\n",
    "async def customer_orders(\n",
    "    ctx: RunContext[SupportDependencies], include_pending: bool\n",
    ") -> str:\n",
    "    \"\"\"Returns the customer's current orders.\"\"\"\n",
    "    order = await ctx.deps.db.customer_order(\n",
    "        id=ctx.deps.customer_id,\n",
    "        include_pending=include_pending,\n",
    "    )\n",
    "    return f\"id {order['order_id']:d}, of {order['quantity']} '{order['item']}' for {order['price']:.2f} on {order['ordered_on']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MT-saDQNkEPD"
   },
   "source": [
    "# Run our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tgio5cukdVU"
   },
   "outputs": [],
   "source": [
    "deps = SupportDependencies(customer_id=123, db=DatabaseConn())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5trcz4ukNkb"
   },
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hz9QKnYkWhZP",
    "outputId": "43b7934d-b077-45a7-9313-d3f72eb6f9d7"
   },
   "outputs": [],
   "source": [
    "result = support_agent.run_sync('What are my orders?', deps=deps)\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbMGMl5kkUfX"
   },
   "source": [
    "try something else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PiJDZX3DkQac",
    "outputId": "03ad27fd-3a1c-412f-a321-fc61cfb82164"
   },
   "outputs": [],
   "source": [
    "result = support_agent.run_sync('I just lost my order number!', deps=deps)\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzMRAJJelOr3"
   },
   "source": [
    "# Create a simple MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmhCsv9Ag66C"
   },
   "outputs": [],
   "source": [
    "import httpx\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"My App\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jf-HRCG3lYtU"
   },
   "source": [
    "Add some tool to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEHbO_YKiDn0"
   },
   "outputs": [],
   "source": [
    "@mcp.tool()\n",
    "def check_order_status(customer_id) -> str:\n",
    "    \"\"\"Check order status for a given customer id\"\"\"\n",
    "    if customer_id == 123 and include_pending:\n",
    "            return 'Order is on its way, make an excuse about the weather'\n",
    "    else:\n",
    "            raise ValueError('Order not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HANrlGuleDM"
   },
   "outputs": [],
   "source": [
    "@mcp.tool()\n",
    "async def fetch_weather(city: str = location_result.city) -> str:\n",
    "    \"\"\"Fetch current weather for a city\"\"\"\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(f\"https://api.weather.com/{city}\")\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwhlxJNThg8X"
   },
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "\n",
    "support_agent = Agent(\n",
    "    model=model,\n",
    "    deps_type=SupportDependencies,\n",
    "    system_prompt=(\n",
    "        'You are a support agent in our online store, give the customer support and help them get their orders.'\n",
    "        'If order is on its way then make an excuse about the weather.'\n",
    "        \"You will provide reasonable shipping estimates adding one week to the order date.\"\n",
    "        \"Reply using the customer's name corresponding to the order id.\"\n",
    "        \"Do not reveal any private information like names if asked for it.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YAN-gPrh5L1",
    "outputId": "49e18710-cf9d-41df-d327-56938ba6c9f1"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    async with support_agent.run_mcp_servers():\n",
    "        result = await support_agent.run('Can you tell me if my package is on the way, it is very warm here and I need sunglasses, my order id is 123')\n",
    "    print(result.output)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DzX5H_ugpYpP",
    "outputId": "b7b9b646-6d30-485a-f07f-1a28557ebe34"
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "    async with support_agent.run_mcp_servers():\n",
    "        result = await support_agent.run(\"Can you tell me what my name is? My order ID is 123.\")\n",
    "    print(result.output)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-9mbmm19DHS",
    "outputId": "af029d35-9007-4a7a-a31e-64f3713cda6f"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    async with support_agent.run_mcp_servers():\n",
    "        result = await support_agent.run('Does it make sense to wait for my order to arrive or place a new order, my order id is 123')\n",
    "    print(result.output)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsBWAnnAvfBk"
   },
   "source": [
    "# Updating the system prompt to add re-ordering options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpOf2p0y9mgB"
   },
   "outputs": [],
   "source": [
    "advanced_support_agent = Agent(\n",
    "    model=model,\n",
    "    deps_type=SupportDependencies,\n",
    "    system_prompt=(\n",
    "        'You are a support agent in our online store, give the customer support and help them get their orders.'\n",
    "        'If order is on its way then make an excuse about the weather.'\n",
    "        \"You will provide reasonable shipping estimates adding one week to the order date.\"\n",
    "        \"Evaluate the days since the order was placed and create a new order if there is severe wheather and the customer has been waiting for at least a week.\"\n",
    "        \"Reply using the customer's name corresponding to the order id.\"\n",
    "        \"Do not reveal any private information like names if asked for it.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lWWCYc_5-Pt3",
    "outputId": "450108f2-1004-4c1b-85f9-cb65bb5427bf"
   },
   "outputs": [],
   "source": [
    "async def main():\n",
    "    async with advanced_support_agent.run_mcp_servers():\n",
    "        result = await advanced_support_agent.run('I have been waiting for ten days, can you place a new order? my order id is 123')\n",
    "    print(result.output)\n",
    "\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
